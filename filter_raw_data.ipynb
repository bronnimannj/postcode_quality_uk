{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter raw data\n",
    "\n",
    "This notebook is to be used locally once when trying to create the filtered raw data to make sure we are able to push our commits to GitHub.\n",
    "\n",
    "We filtered the columns to only be the ones necessary for the analysis. We only took the english postcodes.\n",
    "\n",
    "To save more space, we downcast the numerical columns. All files are saved in file \"data/filtered\".\n",
    "\n",
    "We were able to cut down data size from 1.14GB to 88MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for filtered outputs\n",
    "if not os.path.exists('data/filtered'):\n",
    "    os.mkdir('data/filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_assign(df, transform_fn, condition):\n",
    "    df_to_use = df.copy()\n",
    "\n",
    "    return (df_to_use\n",
    "        .assign(\n",
    "            **{col: transform_fn(df_to_use[col])\n",
    "               for col in condition(df_to_use)})\n",
    "           )\n",
    "           \n",
    "def downcast_all(df, target_type, inital_type=None):\n",
    "    #Gotta specify floats, unsigned, or integer\n",
    "    #If integer, gotta be 'integer', not 'int'\n",
    "    #Unsigned should look for Ints\n",
    "    if inital_type is None:\n",
    "        inital_type = target_type\n",
    "\n",
    "    df_to_use = df.copy()\n",
    "\n",
    "    transform_fn = lambda x: pd.to_numeric(x,\n",
    "                                downcast=target_type)\n",
    "\n",
    "    condition = lambda x: list(x\n",
    "                    .select_dtypes(include=[inital_type])\n",
    "                    .columns)\n",
    "\n",
    "    return multi_assign(df_to_use, transform_fn, condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postcode data\n",
    "This raw data has been sourced from the UK ONS. We need to filter only English postcodes and only the necessary columns to do our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the raw data\n",
    "pcd_raw = pd.read_csv(\"data/raw/NSPL_NOV_2019_UK/NSPL_NOV_2019_UK_RAW.csv\", low_memory= False)\n",
    "\n",
    "# Filter only England postcodes\n",
    "pcd = pcd_raw[pcd_raw['ctry'] == 'E92000001'].copy()\n",
    "\n",
    "# filter only needed columns\n",
    "pcd = pcd.loc[:,[\n",
    "    'pcds',\n",
    "    'lsoa11',\n",
    "    'lat', \n",
    "    'long',\n",
    "    ]]\n",
    "\n",
    "# reset the index to the default one\n",
    "pcd.reset_index(drop = True, inplace= True)\n",
    "\n",
    "# downcast all numerical columns\n",
    "pcd = (pcd\n",
    "    .pipe(downcast_all, \"float\")\n",
    "    .pipe(downcast_all, \"integer\")\n",
    ")\n",
    "\n",
    "# Write into pickle file\n",
    "pcd.to_pickle(\"data/filtered/postcode_filtered.pickle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood data\n",
    "This data has been sourced from https://www.getthedata.com/flood-map/PE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw file\n",
    "flood_raw  = pd.read_csv('data/raw/open_flood_risk_by_postcode.csv')\n",
    "\n",
    "# rename columns as necessary\n",
    "flood_raw.columns = [\n",
    "    'postcode',\n",
    "    'id',\n",
    "    'flood_risk',\n",
    "    'suitability',\n",
    "    'date',\n",
    "    'risk_for_insurance',\n",
    "    'easting',\n",
    "    'northing',\n",
    "    'latitude',\n",
    "    'longitude'\n",
    "    ]\n",
    "\n",
    "# re-create the 2 interesting columns in numerical type to save space\n",
    "flood_raw['flood_risk_int'] = np.select(\n",
    "    condlist = [\n",
    "        flood_raw['flood_risk'] == 'Very Low',\n",
    "        flood_raw['flood_risk'] == 'Low',\n",
    "        flood_raw['flood_risk'] == 'Medium',\n",
    "        flood_raw['flood_risk'] == 'High'\n",
    "    ],\n",
    "    choicelist = [1,2,3,4],\n",
    "    default = 0).astype(int)\n",
    "flood_raw['risk_for_insurance_int'] = (flood_raw['risk_for_insurance'] == 'Yes').astype(int)\n",
    "\n",
    "# only take necessary columns\n",
    "flood = flood_raw.loc[:,[\n",
    "    'postcode',\n",
    "    'flood_risk_int',\n",
    "    'risk_for_insurance_int'\n",
    "    ]]\n",
    "\n",
    "# reset the index to default\n",
    "flood.reset_index(drop = True, inplace= True)\n",
    "\n",
    "# downcast all numerical columns\n",
    "flood = (flood\n",
    "    .pipe(downcast_all, \"float\")\n",
    "    .pipe(downcast_all, \"integer\")\n",
    ")\n",
    "\n",
    "# save file\n",
    "flood.to_pickle(\"data/filtered/flood_risk_filtered.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elevation data\n",
    "The raw data was sourced from https://data.world/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw file\n",
    "elevation_raw  = pd.read_csv(\n",
    "    'data/raw/open_postcode_elevation.csv',\n",
    "    names = ['postcode','elevation']\n",
    ")\n",
    "\n",
    "# downcast all numerical columns\n",
    "elevation_raw = (elevation_raw\n",
    "    .pipe(downcast_all, \"float\")\n",
    "    .pipe(downcast_all, \"integer\")\n",
    ")\n",
    "\n",
    "# save file\n",
    "elevation_raw.to_pickle(\"data/filtered/elevation_filtered.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pets data\n",
    "The raw data was sourced from https://data.world/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw files\n",
    "cats_raw = pd.read_csv(\n",
    "    'data/raw/cat-population-per-postcode-district-1.csv'\n",
    ")\n",
    "dogs_raw = pd.read_csv(\n",
    "    'data/raw/dogs-per-household-per-postcode-district-lower-95th-percentile-1.csv'\n",
    ")\n",
    "\n",
    "# rename columns\n",
    "cats_raw.columns = ['district','estimated_cat_population']\n",
    "dogs_raw.columns = ['district','dog_per_household_lower95']\n",
    "\n",
    "# correct values of column\n",
    "cats_raw['estimated_cat_population'] = cats_raw['estimated_cat_population'].str.replace(',','').astype(float)\n",
    "\n",
    "# merge the 2 data\n",
    "pets = cats_raw.merge(\n",
    "    dogs_raw,\n",
    "    how = 'inner',\n",
    "    on = 'district'\n",
    ")\n",
    "\n",
    "# downcast all numerical columns\n",
    "pets = (pets\n",
    "    .pipe(downcast_all, \"float\")\n",
    "    .pipe(downcast_all, \"integer\")\n",
    ")\n",
    "\n",
    "# save filtered data\n",
    "pets.to_pickle(\"data/filtered/pets_filtered.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index of Multiple Deprivation data\n",
    "The raw data was sourced from https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw file\n",
    "imd_raw = pd.read_excel(\n",
    "    \"data/raw/File_2_-_IoD2019_Domains_of_Deprivation.xlsx\",\n",
    "    sheet_name = 'IoD2019 Domains'\n",
    ")\n",
    "\n",
    "# drop unnecessary columns\n",
    "imd_raw.drop(\n",
    "    [\n",
    "        'LSOA name (2011)',\n",
    "        'Local Authority District code (2019)',\n",
    "        'Local Authority District name (2019)'\n",
    "    ],\n",
    "    axis = 1,\n",
    "    inplace = True\n",
    ")\n",
    "\n",
    "# downcast all numerical columns\n",
    "imd_raw = (imd_raw\n",
    "    .pipe(downcast_all, \"float\")\n",
    "    .pipe(downcast_all, \"integer\")\n",
    ")\n",
    "\n",
    "# save filtered data\n",
    "imd_raw.to_pickle(\"data/filtered/imd_filtered.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1ced07675a5ff60e936cac850907e96edd570f1074109e90be6aeafa0da62fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
